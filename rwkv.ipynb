{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/mambaforge/envs/BioGPT/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch import load as torch_load  # Only for loading the model weights\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = lambda x, w, b : (x - np.mean(x)) / np.std(x) * w + b\n",
    "exp = np.exp\n",
    "sigmoid = lambda x : 1/(1 + exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mixing(x, last_x, last_num, last_den, decay, bonus, mix_k, mix_v, mix_r, Wk, Wv, Wr, Wout):\n",
    "\n",
    "    #   *state[i][:3]: last_x, last_num, last_den\n",
    "    #   *params(f'blocks.{i}.att'): \n",
    "    #   time_decay, time_first, time_mix_k, time_mix_v, time_mix_r, key.weight, value.weight, receptanec.weight, output.weight\n",
    "    #   decay,      bonus,      mix_k,      mix_v,      mix_r,      Wk,         Wv,           Wr,                Wout\n",
    "\n",
    "    k = Wk @ ( x * mix_k + last_x * (1 - mix_k) )\n",
    "    v = Wv @ ( x * mix_v + last_x * (1 - mix_v) )\n",
    "    r = Wr @ ( x * mix_r + last_x * (1 - mix_r) )\n",
    "\n",
    "    wkv = (last_num + exp(bonus + k) * v) / (last_den + exp(bonus + k))\n",
    "    rwkv = sigmoid(r) * wkv\n",
    "\n",
    "    num = exp(-exp(decay)) * last_num + exp(k) * v\n",
    "    den = exp(-exp(decay)) * last_den + exp(k)\n",
    "\n",
    "    return Wout @ rwkv, (x,num,den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_mixing(x, last_x, mix_k, mix_r, Wk, Wr, Wv):\n",
    "    k = Wk @ ( x * mix_k + last_x * (1 - mix_k) )\n",
    "    r = Wr @ ( x * mix_r + last_x * (1 - mix_r) )\n",
    "    vk = Wv @ np.maximum(k, 0)**2\n",
    "    return sigmoid(r) * vk, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RWKV(model, token, state):\n",
    "    # get embedding\n",
    "    params = lambda prefix : [model[key] for key in model.keys() if key.startswith(prefix)]\n",
    "\n",
    "    x = params('emb')[0][token]\n",
    "    x = layer_norm(x, *params('blocks.0.ln0'))\n",
    "\n",
    "    for i in range(N_LAYER):\n",
    "        x_ = layer_norm(x, *params(f'blocks.{i}.ln1'))\n",
    "        dx, state[i][:3] = time_mixing(x_, *state[i][:3], *params(f'blocks.{i}.att'))\n",
    "        x = x + dx\n",
    "\n",
    "        x_ = layer_norm(x, *params(f'blocks.{i}.ln2'))\n",
    "        dx, state[i][3] = channel_mixing(x_, state[i][3], *params(f'blocks.{i}.ffn'))\n",
    "        x = x + dx\n",
    "\n",
    "    x = layer_norm(x, *params('ln_out'))\n",
    "    x = params('head')[0] @ x\n",
    "\n",
    "    e_x = exp(x-np.max(x))\n",
    "    probs = e_x / e_x.sum() # Softmax of x\n",
    "\n",
    "    return probs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_probs(probs, temperature=1.0, top_p=0.85):\n",
    "    sorted_probs = np.sort(probs)[::-1]\n",
    "    cumulative_probs = np.cumsum(sorted_probs)\n",
    "    cutoff = sorted_probs[np.argmax(cumulative_probs > top_p)]\n",
    "    probs[probs < cutoff] = 0\n",
    "    probs = probs**(1/temperature)\n",
    "    # will generate a random number\n",
    "    return np.random.choice(a=len(probs), p=probs/np.sum(probs))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading checkpoints/rwkv_file/RWKV-4-Pile-430M-20220808-8066.pth\n"
     ]
    }
   ],
   "source": [
    "# Available at https://huggingface.co/BlinkDL/rwkv-4-pile-430m/resolve/main/RWKV-4-Pile-430M-20220808-8066.pth\n",
    "MODEL_FILE = 'checkpoints/rwkv_file/RWKV-4-Pile-430M-20220808-8066.pth'\n",
    "N_LAYER = 24\n",
    "N_EMBD = 1024\n",
    "\n",
    "print(f'\\nLoading {MODEL_FILE}')\n",
    "weights = torch_load(MODEL_FILE, map_location='cpu')\n",
    "for k in weights.keys():\n",
    "    if '.time_' in k: weights[k] = weights[k].squeeze()\n",
    "    weights[k] = weights[k].float().numpy() # convert to f32 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['emb.weight', 'blocks.0.ln1.weight', 'blocks.0.ln1.bias', 'blocks.0.ln2.weight', 'blocks.0.ln2.bias', 'blocks.0.att.time_decay', 'blocks.0.att.time_first', 'blocks.0.att.time_mix_k', 'blocks.0.att.time_mix_v', 'blocks.0.att.time_mix_r', 'blocks.0.att.key.weight', 'blocks.0.att.value.weight', 'blocks.0.att.receptance.weight', 'blocks.0.att.output.weight', 'blocks.0.ffn.time_mix_k', 'blocks.0.ffn.time_mix_r', 'blocks.0.ffn.key.weight', 'blocks.0.ffn.receptance.weight', 'blocks.0.ffn.value.weight', 'blocks.0.ln0.weight', 'blocks.0.ln0.bias', 'blocks.1.ln1.weight', 'blocks.1.ln1.bias', 'blocks.1.ln2.weight', 'blocks.1.ln2.bias', 'blocks.1.att.time_decay', 'blocks.1.att.time_first', 'blocks.1.att.time_mix_k', 'blocks.1.att.time_mix_v', 'blocks.1.att.time_mix_r', 'blocks.1.att.key.weight', 'blocks.1.att.value.weight', 'blocks.1.att.receptance.weight', 'blocks.1.att.output.weight', 'blocks.1.ffn.time_mix_k', 'blocks.1.ffn.time_mix_r', 'blocks.1.ffn.key.weight', 'blocks.1.ffn.receptance.weight', 'blocks.1.ffn.value.weight', 'blocks.2.ln1.weight', 'blocks.2.ln1.bias', 'blocks.2.ln2.weight', 'blocks.2.ln2.bias', 'blocks.2.att.time_decay', 'blocks.2.att.time_first', 'blocks.2.att.time_mix_k', 'blocks.2.att.time_mix_v', 'blocks.2.att.time_mix_r', 'blocks.2.att.key.weight', 'blocks.2.att.value.weight', 'blocks.2.att.receptance.weight', 'blocks.2.att.output.weight', 'blocks.2.ffn.time_mix_k', 'blocks.2.ffn.time_mix_r', 'blocks.2.ffn.key.weight', 'blocks.2.ffn.receptance.weight', 'blocks.2.ffn.value.weight', 'blocks.3.ln1.weight', 'blocks.3.ln1.bias', 'blocks.3.ln2.weight', 'blocks.3.ln2.bias', 'blocks.3.att.time_decay', 'blocks.3.att.time_first', 'blocks.3.att.time_mix_k', 'blocks.3.att.time_mix_v', 'blocks.3.att.time_mix_r', 'blocks.3.att.key.weight', 'blocks.3.att.value.weight', 'blocks.3.att.receptance.weight', 'blocks.3.att.output.weight', 'blocks.3.ffn.time_mix_k', 'blocks.3.ffn.time_mix_r', 'blocks.3.ffn.key.weight', 'blocks.3.ffn.receptance.weight', 'blocks.3.ffn.value.weight', 'blocks.4.ln1.weight', 'blocks.4.ln1.bias', 'blocks.4.ln2.weight', 'blocks.4.ln2.bias', 'blocks.4.att.time_decay', 'blocks.4.att.time_first', 'blocks.4.att.time_mix_k', 'blocks.4.att.time_mix_v', 'blocks.4.att.time_mix_r', 'blocks.4.att.key.weight', 'blocks.4.att.value.weight', 'blocks.4.att.receptance.weight', 'blocks.4.att.output.weight', 'blocks.4.ffn.time_mix_k', 'blocks.4.ffn.time_mix_r', 'blocks.4.ffn.key.weight', 'blocks.4.ffn.receptance.weight', 'blocks.4.ffn.value.weight', 'blocks.5.ln1.weight', 'blocks.5.ln1.bias', 'blocks.5.ln2.weight', 'blocks.5.ln2.bias', 'blocks.5.att.time_decay', 'blocks.5.att.time_first', 'blocks.5.att.time_mix_k', 'blocks.5.att.time_mix_v', 'blocks.5.att.time_mix_r', 'blocks.5.att.key.weight', 'blocks.5.att.value.weight', 'blocks.5.att.receptance.weight', 'blocks.5.att.output.weight', 'blocks.5.ffn.time_mix_k', 'blocks.5.ffn.time_mix_r', 'blocks.5.ffn.key.weight', 'blocks.5.ffn.receptance.weight', 'blocks.5.ffn.value.weight', 'blocks.6.ln1.weight', 'blocks.6.ln1.bias', 'blocks.6.ln2.weight', 'blocks.6.ln2.bias', 'blocks.6.att.time_decay', 'blocks.6.att.time_first', 'blocks.6.att.time_mix_k', 'blocks.6.att.time_mix_v', 'blocks.6.att.time_mix_r', 'blocks.6.att.key.weight', 'blocks.6.att.value.weight', 'blocks.6.att.receptance.weight', 'blocks.6.att.output.weight', 'blocks.6.ffn.time_mix_k', 'blocks.6.ffn.time_mix_r', 'blocks.6.ffn.key.weight', 'blocks.6.ffn.receptance.weight', 'blocks.6.ffn.value.weight', 'blocks.7.ln1.weight', 'blocks.7.ln1.bias', 'blocks.7.ln2.weight', 'blocks.7.ln2.bias', 'blocks.7.att.time_decay', 'blocks.7.att.time_first', 'blocks.7.att.time_mix_k', 'blocks.7.att.time_mix_v', 'blocks.7.att.time_mix_r', 'blocks.7.att.key.weight', 'blocks.7.att.value.weight', 'blocks.7.att.receptance.weight', 'blocks.7.att.output.weight', 'blocks.7.ffn.time_mix_k', 'blocks.7.ffn.time_mix_r', 'blocks.7.ffn.key.weight', 'blocks.7.ffn.receptance.weight', 'blocks.7.ffn.value.weight', 'blocks.8.ln1.weight', 'blocks.8.ln1.bias', 'blocks.8.ln2.weight', 'blocks.8.ln2.bias', 'blocks.8.att.time_decay', 'blocks.8.att.time_first', 'blocks.8.att.time_mix_k', 'blocks.8.att.time_mix_v', 'blocks.8.att.time_mix_r', 'blocks.8.att.key.weight', 'blocks.8.att.value.weight', 'blocks.8.att.receptance.weight', 'blocks.8.att.output.weight', 'blocks.8.ffn.time_mix_k', 'blocks.8.ffn.time_mix_r', 'blocks.8.ffn.key.weight', 'blocks.8.ffn.receptance.weight', 'blocks.8.ffn.value.weight', 'blocks.9.ln1.weight', 'blocks.9.ln1.bias', 'blocks.9.ln2.weight', 'blocks.9.ln2.bias', 'blocks.9.att.time_decay', 'blocks.9.att.time_first', 'blocks.9.att.time_mix_k', 'blocks.9.att.time_mix_v', 'blocks.9.att.time_mix_r', 'blocks.9.att.key.weight', 'blocks.9.att.value.weight', 'blocks.9.att.receptance.weight', 'blocks.9.att.output.weight', 'blocks.9.ffn.time_mix_k', 'blocks.9.ffn.time_mix_r', 'blocks.9.ffn.key.weight', 'blocks.9.ffn.receptance.weight', 'blocks.9.ffn.value.weight', 'blocks.10.ln1.weight', 'blocks.10.ln1.bias', 'blocks.10.ln2.weight', 'blocks.10.ln2.bias', 'blocks.10.att.time_decay', 'blocks.10.att.time_first', 'blocks.10.att.time_mix_k', 'blocks.10.att.time_mix_v', 'blocks.10.att.time_mix_r', 'blocks.10.att.key.weight', 'blocks.10.att.value.weight', 'blocks.10.att.receptance.weight', 'blocks.10.att.output.weight', 'blocks.10.ffn.time_mix_k', 'blocks.10.ffn.time_mix_r', 'blocks.10.ffn.key.weight', 'blocks.10.ffn.receptance.weight', 'blocks.10.ffn.value.weight', 'blocks.11.ln1.weight', 'blocks.11.ln1.bias', 'blocks.11.ln2.weight', 'blocks.11.ln2.bias', 'blocks.11.att.time_decay', 'blocks.11.att.time_first', 'blocks.11.att.time_mix_k', 'blocks.11.att.time_mix_v', 'blocks.11.att.time_mix_r', 'blocks.11.att.key.weight', 'blocks.11.att.value.weight', 'blocks.11.att.receptance.weight', 'blocks.11.att.output.weight', 'blocks.11.ffn.time_mix_k', 'blocks.11.ffn.time_mix_r', 'blocks.11.ffn.key.weight', 'blocks.11.ffn.receptance.weight', 'blocks.11.ffn.value.weight', 'blocks.12.ln1.weight', 'blocks.12.ln1.bias', 'blocks.12.ln2.weight', 'blocks.12.ln2.bias', 'blocks.12.att.time_decay', 'blocks.12.att.time_first', 'blocks.12.att.time_mix_k', 'blocks.12.att.time_mix_v', 'blocks.12.att.time_mix_r', 'blocks.12.att.key.weight', 'blocks.12.att.value.weight', 'blocks.12.att.receptance.weight', 'blocks.12.att.output.weight', 'blocks.12.ffn.time_mix_k', 'blocks.12.ffn.time_mix_r', 'blocks.12.ffn.key.weight', 'blocks.12.ffn.receptance.weight', 'blocks.12.ffn.value.weight', 'blocks.13.ln1.weight', 'blocks.13.ln1.bias', 'blocks.13.ln2.weight', 'blocks.13.ln2.bias', 'blocks.13.att.time_decay', 'blocks.13.att.time_first', 'blocks.13.att.time_mix_k', 'blocks.13.att.time_mix_v', 'blocks.13.att.time_mix_r', 'blocks.13.att.key.weight', 'blocks.13.att.value.weight', 'blocks.13.att.receptance.weight', 'blocks.13.att.output.weight', 'blocks.13.ffn.time_mix_k', 'blocks.13.ffn.time_mix_r', 'blocks.13.ffn.key.weight', 'blocks.13.ffn.receptance.weight', 'blocks.13.ffn.value.weight', 'blocks.14.ln1.weight', 'blocks.14.ln1.bias', 'blocks.14.ln2.weight', 'blocks.14.ln2.bias', 'blocks.14.att.time_decay', 'blocks.14.att.time_first', 'blocks.14.att.time_mix_k', 'blocks.14.att.time_mix_v', 'blocks.14.att.time_mix_r', 'blocks.14.att.key.weight', 'blocks.14.att.value.weight', 'blocks.14.att.receptance.weight', 'blocks.14.att.output.weight', 'blocks.14.ffn.time_mix_k', 'blocks.14.ffn.time_mix_r', 'blocks.14.ffn.key.weight', 'blocks.14.ffn.receptance.weight', 'blocks.14.ffn.value.weight', 'blocks.15.ln1.weight', 'blocks.15.ln1.bias', 'blocks.15.ln2.weight', 'blocks.15.ln2.bias', 'blocks.15.att.time_decay', 'blocks.15.att.time_first', 'blocks.15.att.time_mix_k', 'blocks.15.att.time_mix_v', 'blocks.15.att.time_mix_r', 'blocks.15.att.key.weight', 'blocks.15.att.value.weight', 'blocks.15.att.receptance.weight', 'blocks.15.att.output.weight', 'blocks.15.ffn.time_mix_k', 'blocks.15.ffn.time_mix_r', 'blocks.15.ffn.key.weight', 'blocks.15.ffn.receptance.weight', 'blocks.15.ffn.value.weight', 'blocks.16.ln1.weight', 'blocks.16.ln1.bias', 'blocks.16.ln2.weight', 'blocks.16.ln2.bias', 'blocks.16.att.time_decay', 'blocks.16.att.time_first', 'blocks.16.att.time_mix_k', 'blocks.16.att.time_mix_v', 'blocks.16.att.time_mix_r', 'blocks.16.att.key.weight', 'blocks.16.att.value.weight', 'blocks.16.att.receptance.weight', 'blocks.16.att.output.weight', 'blocks.16.ffn.time_mix_k', 'blocks.16.ffn.time_mix_r', 'blocks.16.ffn.key.weight', 'blocks.16.ffn.receptance.weight', 'blocks.16.ffn.value.weight', 'blocks.17.ln1.weight', 'blocks.17.ln1.bias', 'blocks.17.ln2.weight', 'blocks.17.ln2.bias', 'blocks.17.att.time_decay', 'blocks.17.att.time_first', 'blocks.17.att.time_mix_k', 'blocks.17.att.time_mix_v', 'blocks.17.att.time_mix_r', 'blocks.17.att.key.weight', 'blocks.17.att.value.weight', 'blocks.17.att.receptance.weight', 'blocks.17.att.output.weight', 'blocks.17.ffn.time_mix_k', 'blocks.17.ffn.time_mix_r', 'blocks.17.ffn.key.weight', 'blocks.17.ffn.receptance.weight', 'blocks.17.ffn.value.weight', 'blocks.18.ln1.weight', 'blocks.18.ln1.bias', 'blocks.18.ln2.weight', 'blocks.18.ln2.bias', 'blocks.18.att.time_decay', 'blocks.18.att.time_first', 'blocks.18.att.time_mix_k', 'blocks.18.att.time_mix_v', 'blocks.18.att.time_mix_r', 'blocks.18.att.key.weight', 'blocks.18.att.value.weight', 'blocks.18.att.receptance.weight', 'blocks.18.att.output.weight', 'blocks.18.ffn.time_mix_k', 'blocks.18.ffn.time_mix_r', 'blocks.18.ffn.key.weight', 'blocks.18.ffn.receptance.weight', 'blocks.18.ffn.value.weight', 'blocks.19.ln1.weight', 'blocks.19.ln1.bias', 'blocks.19.ln2.weight', 'blocks.19.ln2.bias', 'blocks.19.att.time_decay', 'blocks.19.att.time_first', 'blocks.19.att.time_mix_k', 'blocks.19.att.time_mix_v', 'blocks.19.att.time_mix_r', 'blocks.19.att.key.weight', 'blocks.19.att.value.weight', 'blocks.19.att.receptance.weight', 'blocks.19.att.output.weight', 'blocks.19.ffn.time_mix_k', 'blocks.19.ffn.time_mix_r', 'blocks.19.ffn.key.weight', 'blocks.19.ffn.receptance.weight', 'blocks.19.ffn.value.weight', 'blocks.20.ln1.weight', 'blocks.20.ln1.bias', 'blocks.20.ln2.weight', 'blocks.20.ln2.bias', 'blocks.20.att.time_decay', 'blocks.20.att.time_first', 'blocks.20.att.time_mix_k', 'blocks.20.att.time_mix_v', 'blocks.20.att.time_mix_r', 'blocks.20.att.key.weight', 'blocks.20.att.value.weight', 'blocks.20.att.receptance.weight', 'blocks.20.att.output.weight', 'blocks.20.ffn.time_mix_k', 'blocks.20.ffn.time_mix_r', 'blocks.20.ffn.key.weight', 'blocks.20.ffn.receptance.weight', 'blocks.20.ffn.value.weight', 'blocks.21.ln1.weight', 'blocks.21.ln1.bias', 'blocks.21.ln2.weight', 'blocks.21.ln2.bias', 'blocks.21.att.time_decay', 'blocks.21.att.time_first', 'blocks.21.att.time_mix_k', 'blocks.21.att.time_mix_v', 'blocks.21.att.time_mix_r', 'blocks.21.att.key.weight', 'blocks.21.att.value.weight', 'blocks.21.att.receptance.weight', 'blocks.21.att.output.weight', 'blocks.21.ffn.time_mix_k', 'blocks.21.ffn.time_mix_r', 'blocks.21.ffn.key.weight', 'blocks.21.ffn.receptance.weight', 'blocks.21.ffn.value.weight', 'blocks.22.ln1.weight', 'blocks.22.ln1.bias', 'blocks.22.ln2.weight', 'blocks.22.ln2.bias', 'blocks.22.att.time_decay', 'blocks.22.att.time_first', 'blocks.22.att.time_mix_k', 'blocks.22.att.time_mix_v', 'blocks.22.att.time_mix_r', 'blocks.22.att.key.weight', 'blocks.22.att.value.weight', 'blocks.22.att.receptance.weight', 'blocks.22.att.output.weight', 'blocks.22.ffn.time_mix_k', 'blocks.22.ffn.time_mix_r', 'blocks.22.ffn.key.weight', 'blocks.22.ffn.receptance.weight', 'blocks.22.ffn.value.weight', 'blocks.23.ln1.weight', 'blocks.23.ln1.bias', 'blocks.23.ln2.weight', 'blocks.23.ln2.bias', 'blocks.23.att.time_decay', 'blocks.23.att.time_first', 'blocks.23.att.time_mix_k', 'blocks.23.att.time_mix_v', 'blocks.23.att.time_mix_r', 'blocks.23.att.key.weight', 'blocks.23.att.value.weight', 'blocks.23.att.receptance.weight', 'blocks.23.att.output.weight', 'blocks.23.ffn.time_mix_k', 'blocks.23.ffn.time_mix_r', 'blocks.23.ffn.key.weight', 'blocks.23.ffn.receptance.weight', 'blocks.23.ffn.value.weight', 'ln_out.weight', 'ln_out.bias', 'head.weight'])\n"
     ]
    }
   ],
   "source": [
    "print(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.from_file(\"checkpoints/rwkv_file/20B_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing context\n",
      "(24, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nPreprocessing context')\n",
    "\n",
    "context = \"\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\"\n",
    "\n",
    "state = np.zeros((N_LAYER, 4, N_EMBD), dtype=np.float32)\n",
    "print(state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokenizer.encode(context).ids:\n",
    "    probs, state = RWKV(weights, token, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "\n",
      "The international team of scientists say they found evidence of three dragons, sharing one tongue, with “chosen” and “white” dragons.\n",
      "\n",
      "The work was conducted by Dr Haijing Chen, of the Chinese Academy of Sciences, and her team from the Academy of Chinese Academy of Sciences, China Academy of Sciences.\n",
      "\n",
      "“We detected these three dragons and their descendants, along with their grandchildren, in the high mountainous region of Tibet,” says Chen. “This is a rare"
     ]
    }
   ],
   "source": [
    "print(context, end=\"\")\n",
    "for i in range(100):\n",
    "    token = sample_probs(probs)\n",
    "    print(tokenizer.decode([token]), end=\"\", flush=True)\n",
    "    probs, state = RWKV(weights, token, state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer.encode(context).ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = lambda prefix : [weights[key] for key in weights.keys() if key.startswith(prefix)]\n",
    "x = params('emb')[0][token]\n",
    "x = layer_norm(x, *params('blocks.0.ln0'))\n",
    "i = 0\n",
    "x_ = layer_norm(x, *params(f'blocks.{i}.ln1'))\n",
    "# dx, state[i][:3] = time_mixing(x_, *state[i][:3], *params(f'blocks.{i}.att'))\n",
    "_x, last_x, last_num, last_den, decay, bonus, mix_k, mix_v, mix_r, Wk, Wv, Wr, Wout = \\\n",
    "    x_, *state[i][:3], *params(f'blocks.{i}.att')\n",
    "k = Wk @ ( _x * mix_k + last_x * (1 - mix_k) )\n",
    "v = Wv @ ( _x * mix_v + last_x * (1 - mix_v) )\n",
    "r = Wr @ ( _x * mix_r + last_x * (1 - mix_r) )\n",
    "\n",
    "wkv = (last_num + exp(bonus + k) * v) / (last_den + exp(bonus + k))\n",
    "rwkv = sigmoid(r) * wkv\n",
    "num = exp(-exp(decay)) * last_num + exp(k) * v\n",
    "den = exp(-exp(decay)) * last_den + exp(k)\n",
    "dx = Wout @ rwkv\n",
    "state[i][:3] = (_x,num,den)\n",
    "\n",
    "x = x + dx\n",
    "\n",
    "x_ = layer_norm(x, *params(f'blocks.{i}.ln2'))\n",
    "\n",
    "# dx, state[i][3] = channel_mixing(x_, state[i][3], *params(f'blocks.{i}.ffn'))\n",
    "_x, last_x, mix_k, mix_r, Wk, Wr, Wv = x_, state[i][3], *params(f'blocks.{i}.ffn')\n",
    "k = Wk @ ( _x * mix_k + last_x * (1 - mix_k) )\n",
    "r = Wr @ ( _x * mix_r + last_x * (1 - mix_r) )\n",
    "vk = Wv @ np.maximum(k, 0)**2\n",
    "dx, state[i][3] = sigmoid(r) * vk, _x\n",
    "\n",
    "x = x + dx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 1024)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wk.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
