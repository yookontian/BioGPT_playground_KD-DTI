{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pred_T file and the gold file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = 'analysis/predT_not_in_original_pmid_predTs.json'\n",
    "gold_file = 'data/KD-DTI/raw/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823\n",
      "{'id': '11169165', 'predT_not_in_original': ['monoamine oxidase type b (mao-b)', 'monoamine oxidase type a (mao-a)']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# load the pmids that the pred_Ts are not in the original articles\n",
    "with open (pred_file, 'r') as f:\n",
    "    pred_d_not_in_original = json.load(f)\n",
    "\n",
    "print(len(pred_d_not_in_original))\n",
    "print(pred_d_not_in_original[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159\n",
      "{'title': 'Inhibition of rat brain monoamine oxidase activities by psoralen and isopsoralen: implications for the treatment of affective disorders.', 'abstract': 'Psoralen and isopsoralen, furocoumarins isolated from the plant Psoralea corylifolia L., were demonstrated to exhibit in vitro inhibitory actions on monoamine oxidase (MAO) activities in rat brain mitochondria, preferentially inhibiting MAO-A activity over MAO-B activity. This inhibition of enzyme activities was found to be dose-dependent and reversible. For MAO-A, the IC50 values are 15.2 +/- 1.3 microM psoralen and 9.0 +/- 0.6 microM isopsoralen. For MAO-B, the IC50 values are 61.8 +/- 4.3 microM psoralen and 12.8 +/- 0.5 microM isopsoralen. Lineweaver-Burk transformation of the inhibition data indicates that inhibition by both psoralen and isopsoralen is non-competitive for MAO-A. The Ki values were calculated to be 14.0 microM for psoralen and 6.5 microM for isopsoralen. On the other hand, inhibition by both psoralen and isopsoralen is competitive for MAO-B. The Ki values were calculated to be 58.1 microM for psoralen and 10.8 microM for isopsoralen. These inhibitory actions of psoralen and isopsoralen on rat brain mitochondrial MAO activities are discussed in relation to their toxicities and their potential applications to treat affective disorders.', 'triples': [{'drug': 'Psoralen', 'target': 'Monoamine oxidase type A (MAO-A)', 'interaction': 'inhibitor'}, {'drug': 'Psoralen', 'target': 'Monoamine oxidase type B (MAO-B)', 'interaction': 'inhibitor'}], 'pmid': '11169165'}\n"
     ]
    }
   ],
   "source": [
    "# load the gold standard\n",
    "with open (gold_file, 'r') as f:\n",
    "    gold_d = json.load(f)\n",
    "\n",
    "print(len(gold_d))\n",
    "print(gold_d[pred_d_not_in_original[0]['id']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tian/mambaforge/envs/BioGPT/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-11 18:18:19 | INFO | fairseq.file_utils | loading archive file checkpoints/RE-DTI-BioGPT\n",
      "2023-04-11 18:18:19 | INFO | fairseq.file_utils | loading archive file data/KD-DTI/relis-bin\n",
      "2023-04-11 18:18:20 | INFO | src.language_modeling_prompt | dictionary: 42384 types\n",
      "2023-04-11 18:18:23 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': '../../src', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 30, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [32], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '../../checkpoints/RE-DTI-BioGPT', 'restore_file': '../../checkpoints/Pre-trained-BioGPT/checkpoint.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 1024, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_prompt_biogpt', 'activation_fn': 'gelu', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.0, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 24, 'decoder_attention_heads': 16, 'decoder_normalize_before': True, 'no_decoder_final_norm': False, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.0, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': True, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': False, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': False, 'tie_adaptive_proj': False, 'decoder_learned_pos': True, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': 1024, 'tpu': False, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False}, 'task': {'_name': 'language_modeling_prompt', 'data': 'data/KD-DTI/relis-bin', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': 1024, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'source_lang': None, 'target_lang': None, 'max_source_positions': 640, 'manual_prompt': None, 'learned_prompt': 9, 'learned_prompt_pattern': 'learned', 'prefix': False, 'sep_token': '<seqsep>'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 1000, 'warmup_init_lr': 1e-07, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'fastbpe', 'bpe_codes': 'data/bpecodes'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'en', 'moses_no_dash_splits': False, 'moses_no_escape': False}}\n",
      "Loading codes from data/bpecodes ...\n",
      "Read 40000 codes from the codes file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneratorHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): TransformerLanguageModelPrompt(\n",
       "      (decoder): TransformerDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(42393, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): TransformerDecoderLayerBase(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (output_projection): Linear(in_features=1024, out_features=42393, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.transformer_lm_prompt import TransformerLanguageModelPrompt\n",
    "m = TransformerLanguageModelPrompt.from_pretrained(\n",
    "        \"checkpoints/RE-DTI-BioGPT\", \n",
    "        \"checkpoint_avg.pt\", \n",
    "        \"data/KD-DTI/relis-bin\",\n",
    "        tokenizer='moses', \n",
    "        bpe='fastbpe', \n",
    "        bpe_codes=\"data/bpecodes\",\n",
    "        max_len_b=1024,\n",
    "        beam=5)\n",
    "m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because it's hard to use the moses tokenizer.decode() to show the different between the 4 (= 4#) and 4</w>\n",
    "# so here using the tokenizer from HF to decode each generated token, and it doesn't include the learn0 - learn9, which is not a problem\n",
    "from transformers import BioGptTokenizer\n",
    "\n",
    "tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a test data: {\"pmid\": ,\n",
    "#               \"id\": ,\n",
    "#               \"title+abstract.lower()\": ,\n",
    "#               \"text_tokens\": ,\n",
    "#               \"pred_Ts\": ,\n",
    "#              \"pred_Ts_tokens\": ,}\n",
    "#               \"gold_triples\": ,}\n",
    "\n",
    "def get_test_data(id):\n",
    "    prefix = torch.arange(42384, 42393)\n",
    "    test_data = {}\n",
    "    test_data['pmid'] = pred_d_not_in_original[id]['id']\n",
    "    test_data['text'] = gold_d[test_data['pmid']]['title'].strip() + \" \" + gold_d[test_data['pmid']]['abstract']\n",
    "    test_data['text'] = test_data['text'].lower().strip().replace('  ', ' ')\n",
    "    test_data['text_tokens'] = m.encode(test_data['text'])\n",
    "    test_data['text_tokens_with_prefix'] = torch.cat([test_data['text_tokens'], prefix], dim=-1).unsqueeze(0).cuda()\n",
    "    test_data['pred_Ts'] = pred_d_not_in_original[id]['predT_not_in_original']\n",
    "    test_data['pred_Ts_tokens'] = [m.encode(pred_T) for pred_T in test_data['pred_Ts']]\n",
    "    test_data['gold_triples'] = gold_d[test_data['pmid']]['triples']\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"pred_Ds\": \"nitric-oxide synthase inducible (nos2)\",\n",
      "\"gold\": {'drug': '3-Bromo-1H-indazole-7-carbonitrile', 'target': 'Nitric-oxide synthase brain (NOS1)', 'interaction': 'inhibitor'},\n",
      "\"text\": \"inhibitory effects of a series of 7-substituted-indazoles toward nitric oxide synthases: particular potency of 1h-indazole-7-carbonitrile. a series of new 7-monosubstituted and 3,7-disubstituted indazoles have been prepared and evaluated as inhibitors of nitric oxide synthases (nos). 1h-indazole-7-carbonitrile (6) was found equipotent to 7-nitro-1h-indazole (1) and demonstrated preference for constitutive nos over inducible nos. by contrast, 1h-indazole-7-carboxamide (8) was slightly less potent but demonstrated a surprising selectivity for the neuronal nos. further substitution of 6 by a br-atom at carbon-3 of the heterocycle enhanced 10-fold the inhibitory effects. inhibition of no formation by 6 appeared to be competitive versus both substrate and the cofactor (6r)-5,6,7,8-tetrahydro-l-biopterin (h(4)b). in close analogies with 1, compound 6 strongly inhibited the nadph oxidase activity of nnos and induced a spin state transition of the heme-fe(iii). our results are explained with the help of the x-ray structures that identified key-features for binding of 1 at the active site of nos.\"\n"
     ]
    }
   ],
   "source": [
    "test_data = get_test_data(18)\n",
    "\n",
    "print(f'\"pred_Ds\": \"{test_data[\"pred_Ts\"][0]}\",')\n",
    "print(f'\"gold\": {test_data[\"gold_triples\"][0]},')\n",
    "print(f'\"text\": \"{test_data[\"text\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"10130\": \"xanthine</w>\",\n",
      "\"2025\": \"derivatives</w>\",\n",
      "\"2898\": \"ib\",\n",
      "\"676\": \"m\",\n",
      "\"543\": \"x</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"279\": \"s</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"11770\": \"77\",\n",
      "\"2404\": \"99</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"40\": \"2</w>\",\n",
      "\"16227\": \"potentiate</w>\",\n",
      "\"1323\": \"transmission</w>\",\n",
      "\"34\": \"at</w>\",\n",
      "\"32\": \"an</w>\",\n",
      "\"806\": \"a\",\n",
      "\"2234\": \"pl\",\n",
      "\"39074\": \"ysia</w>\",\n",
      "\"698\": \"central</w>\",\n",
      "\"4961\": \"cholinergic</w>\",\n",
      "\"13988\": \"synap\",\n",
      "\"3265\": \"se\",\n",
      "\"4\": \".</w>\",\n",
      "\"10\": \"in</w>\",\n",
      "\"32\": \"an</w>\",\n",
      "\"3662\": \"attempt</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"559\": \"investigate</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"151\": \"role</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"8490\": \"cam\",\n",
      "\"110\": \"p</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"267\": \"dependent</w>\",\n",
      "\"21498\": \"phosphoryl\",\n",
      "\"1184\": \"ations</w>\",\n",
      "\"25\": \"on</w>\",\n",
      "\"2483\": \"synaptic</w>\",\n",
      "\"1323\": \"transmission</w>\",\n",
      "\"34\": \"at</w>\",\n",
      "\"32\": \"an</w>\",\n",
      "\"806\": \"a\",\n",
      "\"2234\": \"pl\",\n",
      "\"39074\": \"ysia</w>\",\n",
      "\"4961\": \"cholinergic</w>\",\n",
      "\"10077\": \"buccal</w>\",\n",
      "\"4824\": \"ganglion</w>\",\n",
      "\"12508\": \"synapse</w>\",\n",
      "\"7\": \",</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"92\": \"effects</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"10130\": \"xanthine</w>\",\n",
      "\"2025\": \"derivatives</w>\",\n",
      "\"147\": \"such</w>\",\n",
      "\"27\": \"as</w>\",\n",
      "\"54\": \"3</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"34237\": \"isobutyl</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"36\": \"1</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"2055\": \"methyl\",\n",
      "\"10130\": \"xanthine</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"2898\": \"ib\",\n",
      "\"676\": \"m\",\n",
      "\"543\": \"x</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"7\": \",</w>\",\n",
      "\"46\": \"which</w>\",\n",
      "\"21\": \"is</w>\",\n",
      "\"126\": \"well</w>\",\n",
      "\"382\": \"known</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"1712\": \"inhibit</w>\",\n",
      "\"10434\": \"phosphodiesterase</w>\",\n",
      "\"79\": \"activity</w>\",\n",
      "\"2788\": \"thereby</w>\",\n",
      "\"3090\": \"promoting</w>\",\n",
      "\"8490\": \"cam\",\n",
      "\"110\": \"p</w>\",\n",
      "\"1182\": \"accumulation</w>\",\n",
      "\"7\": \",</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"14\": \"a</w>\",\n",
      "\"409\": \"novel</w>\",\n",
      "\"10130\": \"xanthine</w>\",\n",
      "\"3911\": \"derivative</w>\",\n",
      "\"7\": \",</w>\",\n",
      "\"279\": \"s</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"11770\": \"77\",\n",
      "\"2404\": \"99</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"40\": \"2</w>\",\n",
      "\"19\": \"were</w>\",\n",
      "\"28167\": \"evalu\",\n",
      "\"36156\": \"ated\",\n",
      "\"4\": \".</w>\",\n",
      "\"298\": \"they</w>\",\n",
      "\"19\": \"were</w>\",\n",
      "\"95\": \"found</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"16227\": \"potentiate</w>\",\n",
      "\"4961\": \"cholinergic</w>\",\n",
      "\"1323\": \"transmission</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"90\": \"significantly</w>\",\n",
      "\"623\": \"increasing</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"94\": \"time</w>\",\n",
      "\"1575\": \"constant</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"5628\": \"decay</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"765\": \"t\",\n",
      "\"457\": \"c</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"1166\": \"inhibitory</w>\",\n",
      "\"7628\": \"postsynaptic</w>\",\n",
      "\"4414\": \"currents</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"2740\": \"ip\",\n",
      "\"2861\": \"sc\",\n",
      "\"279\": \"s</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"4\": \".</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"7628\": \"postsynaptic</w>\",\n",
      "\"1494\": \"origin</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"2629\": \"phenomenon</w>\",\n",
      "\"17\": \"was</w>\",\n",
      "\"2314\": \"supported</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"1930\": \"observation</w>\",\n",
      "\"22\": \"that</w>\",\n",
      "\"384\": \"responses</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"6435\": \"ion\",\n",
      "\"3388\": \"oph\",\n",
      "\"28924\": \"oretic</w>\",\n",
      "\"773\": \"application</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"4406\": \"acetylcholine</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"8061\": \"ach</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"19\": \"were</w>\",\n",
      "\"72\": \"also</w>\",\n",
      "\"8703\": \"potentiated</w>\",\n",
      "\"10\": \"in</w>\",\n",
      "\"758\": \"duration</w>\",\n",
      "\"27\": \"as</w>\",\n",
      "\"126\": \"well</w>\",\n",
      "\"27\": \"as</w>\",\n",
      "\"10\": \"in</w>\",\n",
      "\"15653\": \"ampl\",\n",
      "\"19287\": \"itu\",\n",
      "\"978\": \"de\",\n",
      "\"4\": \".</w>\",\n",
      "\"102\": \"no</w>\",\n",
      "\"92\": \"effects</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"279\": \"s</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"11770\": \"77\",\n",
      "\"2404\": \"99</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"40\": \"2</w>\",\n",
      "\"25\": \"on</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"8061\": \"ach</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"6791\": \"gated</w>\",\n",
      "\"2188\": \"cl\",\n",
      "\"81\": \"-</w>\",\n",
      "\"1415\": \"channel</w>\",\n",
      "\"4949\": \"conductance</w>\",\n",
      "\"30\": \"or</w>\",\n",
      "\"187\": \"mean</w>\",\n",
      "\"975\": \"open</w>\",\n",
      "\"94\": \"time</w>\",\n",
      "\"19\": \"were</w>\",\n",
      "\"37867\": \"obser\",\n",
      "\"4698\": \"ve\",\n",
      "\"32935\": \"d.</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"1710\": \"finding</w>\",\n",
      "\"22\": \"that</w>\",\n",
      "\"384\": \"responses</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"3347\": \"hydrolysis</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"867\": \"resistant</w>\",\n",
      "\"4961\": \"cholinergic</w>\",\n",
      "\"4535\": \"analogue</w>\",\n",
      "\"12427\": \"carbachol</w>\",\n",
      "\"19\": \"were</w>\",\n",
      "\"4171\": \"unaffected</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"65\": \"two</w>\",\n",
      "\"11202\": \"xanth\",\n",
      "\"2945\": \"ines</w>\",\n",
      "\"756\": \"suggested</w>\",\n",
      "\"22\": \"that</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"138\": \"observed</w>\",\n",
      "\"92\": \"effects</w>\",\n",
      "\"19\": \"were</w>\",\n",
      "\"34\": \"at</w>\",\n",
      "\"660\": \"least</w>\",\n",
      "\"4729\": \"partly</w>\",\n",
      "\"518\": \"caused</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"32\": \"an</w>\",\n",
      "\"468\": \"inhibition</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"11802\": \"acetylcholinesterase</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"28531\": \"ache</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"14960\": \"activ\",\n",
      "\"1432\": \"it\",\n",
      "\"1066\": \"y\",\n",
      "\"4\": \".</w>\",\n",
      "\"22\": \"that</w>\",\n",
      "\"55\": \"these</w>\",\n",
      "\"3205\": \"substances</w>\",\n",
      "\"1712\": \"inhibit</w>\",\n",
      "\"28531\": \"ache</w>\",\n",
      "\"79\": \"activity</w>\",\n",
      "\"17\": \"was</w>\",\n",
      "\"755\": \"confirmed</w>\",\n",
      "\"10\": \"in</w>\",\n",
      "\"11058\": \"vit\",\n",
      "\"1309\": \"ro\",\n",
      "\"4\": \".</w>\",\n",
      "\"1293\": \"phosphorylation</w>\",\n",
      "\"721\": \"processes</w>\",\n",
      "\"34594\": \"nonetheless</w>\",\n",
      "\"1536\": \"appear</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"33\": \"be</w>\",\n",
      "\"4729\": \"partly</w>\",\n",
      "\"396\": \"involved</w>\",\n",
      "\"10\": \"in</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"2483\": \"synaptic</w>\",\n",
      "\"96\": \"effect</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"11202\": \"xanth\",\n",
      "\"2945\": \"ines</w>\",\n",
      "\"27\": \"as</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"617\": \"kinase</w>\",\n",
      "\"6304\": \"blocker</w>\",\n",
      "\"259\": \"h</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"208\": \"8</w>\",\n",
      "\"2506\": \"blocked</w>\",\n",
      "\"672\": \"part</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"2740\": \"ip\",\n",
      "\"17524\": \"sc</w>\",\n",
      "\"765\": \"t\",\n",
      "\"457\": \"c</w>\",\n",
      "\"35512\": \"leng\",\n",
      "\"29397\": \"then\",\n",
      "\"3469\": \"ing\",\n",
      "\"4\": \".</w>\",\n",
      "\"416\": \"possible</w>\",\n",
      "\"397\": \"mechanisms</w>\",\n",
      "\"31\": \"are</w>\",\n",
      "\"728\": \"discussed</w>\",\n",
      "\"4\": \".</w>\",\n",
      "\"2\": \"</s>\",\n",
      "\"42384\": \"<unk>\",\n",
      "\"42385\": \"<unk>\",\n",
      "\"42386\": \"<unk>\",\n",
      "\"42387\": \"<unk>\",\n",
      "\"42388\": \"<unk>\",\n",
      "\"42389\": \"<unk>\",\n",
      "\"42390\": \"<unk>\",\n",
      "\"42391\": \"<unk>\",\n",
      "\"42392\": \"<unk>\",\n"
     ]
    }
   ],
   "source": [
    "prefix = torch.arange(42384, 42393)\n",
    "texts = \"xanthine derivatives ibmx and s-7799-2 potentiate transmission at an aplysia central cholinergic synapse. in an attempt to investigate the role of camp-dependent phosphorylations on synaptic transmission at an aplysia cholinergic buccal ganglion synapse, the effects of xanthine derivatives such as 3-isobutyl-1-methylxanthine (ibmx), which is well known to inhibit phosphodiesterase activity thereby promoting camp accumulation, and a novel xanthine derivative, s-7799-2 were evaluated. they were found to potentiate cholinergic transmission by significantly increasing the time constant of decay (tc) of inhibitory postsynaptic currents (ipscs). the postsynaptic origin of the phenomenon was supported by the observation that responses to the ionophoretic application of acetylcholine (ach) were also potentiated in duration as well as in amplitude. no effects of s-7799-2 on the ach-gated cl- channel conductance or mean open time were observed. the finding that responses to the hydrolysis-resistant cholinergic analogue carbachol were unaffected by the two xanthines suggested that the observed effects were at least partly caused by an inhibition of acetylcholinesterase (ache) activity. that these substances inhibit ache activity was confirmed in vitro. phosphorylation processes nonetheless appear to be partly involved in the synaptic effect of the xanthines as the kinase blocker h-8 blocked part of the ipsc tc lengthening. possible mechanisms are discussed.\"\n",
    "tokens = m.encode(texts)\n",
    "test_dataa = torch.cat([tokens, prefix], dim=-1).unsqueeze(0).cuda()\n",
    "for token_id in test_dataa[0]:\n",
    "    print(f'\"{token_id.item()}\": \"{tokenizer.convert_ids_to_tokens([token_id])[0]}\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1166\": \"inhibitory</w>\",\n",
      "\"92\": \"effects</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"14\": \"a</w>\",\n",
      "\"870\": \"series</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"4225\": \"substituted</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5755\": \"ind\",\n",
      "\"22572\": \"azoles</w>\",\n",
      "\"1542\": \"toward</w>\",\n",
      "\"2624\": \"nitric</w>\",\n",
      "\"1279\": \"oxide</w>\",\n",
      "\"26552\": \"synthases</w>\",\n",
      "\"20\": \":</w>\",\n",
      "\"1034\": \"particular</w>\",\n",
      "\"4051\": \"potency</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"926\": \"1\",\n",
      "\"259\": \"h</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5755\": \"ind\",\n",
      "\"6633\": \"azole</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5319\": \"carb\",\n",
      "\"36797\": \"onitr\",\n",
      "\"1628\": \"il\",\n",
      "\"36448\": \"e.</w>\",\n",
      "\"14\": \"a</w>\",\n",
      "\"870\": \"series</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"176\": \"new</w>\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"14136\": \"monos\",\n",
      "\"33448\": \"ubstituted</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"4273\": \"3,\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"33361\": \"disubstituted</w>\",\n",
      "\"5755\": \"ind\",\n",
      "\"22572\": \"azoles</w>\",\n",
      "\"47\": \"have</w>\",\n",
      "\"58\": \"been</w>\",\n",
      "\"1380\": \"prepared</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"330\": \"evaluated</w>\",\n",
      "\"27\": \"as</w>\",\n",
      "\"891\": \"inhibitors</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"2624\": \"nitric</w>\",\n",
      "\"1279\": \"oxide</w>\",\n",
      "\"26552\": \"synthases</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"37199\": \"nos</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"4\": \".</w>\",\n",
      "\"926\": \"1\",\n",
      "\"259\": \"h</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5755\": \"ind\",\n",
      "\"6633\": \"azole</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5319\": \"carb\",\n",
      "\"17149\": \"onitrile</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"116\": \"6</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"17\": \"was</w>\",\n",
      "\"95\": \"found</w>\",\n",
      "\"32612\": \"equipot\",\n",
      "\"2012\": \"ent</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"10316\": \"nitro</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"926\": \"1\",\n",
      "\"259\": \"h</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5755\": \"ind\",\n",
      "\"6633\": \"azole</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"36\": \"1</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"301\": \"demonstrated</w>\",\n",
      "\"3998\": \"preference</w>\",\n",
      "\"16\": \"for</w>\",\n",
      "\"7042\": \"constitutive</w>\",\n",
      "\"37199\": \"nos</w>\",\n",
      "\"222\": \"over</w>\",\n",
      "\"3905\": \"inducible</w>\",\n",
      "\"9942\": \"nos\",\n",
      "\"4\": \".</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"476\": \"contrast</w>\",\n",
      "\"7\": \",</w>\",\n",
      "\"926\": \"1\",\n",
      "\"259\": \"h</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5755\": \"ind\",\n",
      "\"6633\": \"azole</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"215\": \"7</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"28807\": \"carboxamide</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"208\": \"8</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"17\": \"was</w>\",\n",
      "\"2195\": \"slightly</w>\",\n",
      "\"188\": \"less</w>\",\n",
      "\"1583\": \"potent</w>\",\n",
      "\"61\": \"but</w>\",\n",
      "\"301\": \"demonstrated</w>\",\n",
      "\"14\": \"a</w>\",\n",
      "\"16556\": \"surprising</w>\",\n",
      "\"3952\": \"selectivity</w>\",\n",
      "\"16\": \"for</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"1389\": \"neuronal</w>\",\n",
      "\"9942\": \"nos\",\n",
      "\"4\": \".</w>\",\n",
      "\"345\": \"further</w>\",\n",
      "\"3892\": \"substitution</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"116\": \"6</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"14\": \"a</w>\",\n",
      "\"697\": \"b\",\n",
      "\"677\": \"r</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"5116\": \"atom</w>\",\n",
      "\"34\": \"at</w>\",\n",
      "\"1274\": \"carbon</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"54\": \"3</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"28337\": \"heterocy\",\n",
      "\"11204\": \"cle</w>\",\n",
      "\"685\": \"enhanced</w>\",\n",
      "\"91\": \"10</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"858\": \"fold</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"1166\": \"inhibitory</w>\",\n",
      "\"23157\": \"effec\",\n",
      "\"11830\": \"ts\",\n",
      "\"4\": \".</w>\",\n",
      "\"468\": \"inhibition</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"102\": \"no</w>\",\n",
      "\"381\": \"formation</w>\",\n",
      "\"23\": \"by</w>\",\n",
      "\"116\": \"6</w>\",\n",
      "\"1568\": \"appeared</w>\",\n",
      "\"13\": \"to</w>\",\n",
      "\"33\": \"be</w>\",\n",
      "\"4000\": \"competitive</w>\",\n",
      "\"666\": \"versus</w>\",\n",
      "\"74\": \"both</w>\",\n",
      "\"1264\": \"substrate</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"9911\": \"cofactor</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"393\": \"6\",\n",
      "\"677\": \"r</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"185\": \"-\",\n",
      "\"4987\": \"5,\",\n",
      "\"6722\": \"6,\",\n",
      "\"18926\": \"7,8</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"30506\": \"tetrahydro</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"688\": \"l</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"33592\": \"biopterin</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"259\": \"h</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"85\": \"4</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"787\": \"b</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"4\": \".</w>\",\n",
      "\"10\": \"in</w>\",\n",
      "\"1882\": \"close</w>\",\n",
      "\"35368\": \"analog\",\n",
      "\"3045\": \"ies</w>\",\n",
      "\"15\": \"with</w>\",\n",
      "\"36\": \"1</w>\",\n",
      "\"7\": \",</w>\",\n",
      "\"1616\": \"compound</w>\",\n",
      "\"116\": \"6</w>\",\n",
      "\"1318\": \"strongly</w>\",\n",
      "\"719\": \"inhibited</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"34618\": \"nad\",\n",
      "\"13099\": \"ph</w>\",\n",
      "\"3183\": \"oxidase</w>\",\n",
      "\"79\": \"activity</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"790\": \"n\",\n",
      "\"37199\": \"nos</w>\",\n",
      "\"8\": \"and</w>\",\n",
      "\"120\": \"induced</w>\",\n",
      "\"14\": \"a</w>\",\n",
      "\"3556\": \"spin</w>\",\n",
      "\"489\": \"state</w>\",\n",
      "\"1513\": \"transition</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"5375\": \"heme</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"871\": \"f\",\n",
      "\"707\": \"e</w>\",\n",
      "\"12\": \"(</w>\",\n",
      "\"5617\": \"iii</w>\",\n",
      "\"11\": \")</w>\",\n",
      "\"4\": \".</w>\",\n",
      "\"218\": \"our</w>\",\n",
      "\"62\": \"results</w>\",\n",
      "\"31\": \"are</w>\",\n",
      "\"2642\": \"explained</w>\",\n",
      "\"15\": \"with</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"1159\": \"help</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"543\": \"x</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"1489\": \"ray</w>\",\n",
      "\"788\": \"structures</w>\",\n",
      "\"22\": \"that</w>\",\n",
      "\"220\": \"identified</w>\",\n",
      "\"822\": \"key</w>\",\n",
      "\"9\": \"@-@</w>\",\n",
      "\"585\": \"features</w>\",\n",
      "\"16\": \"for</w>\",\n",
      "\"201\": \"binding</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"36\": \"1</w>\",\n",
      "\"34\": \"at</w>\",\n",
      "\"6\": \"the</w>\",\n",
      "\"426\": \"active</w>\",\n",
      "\"455\": \"site</w>\",\n",
      "\"5\": \"of</w>\",\n",
      "\"37199\": \"nos</w>\",\n",
      "\"4\": \".</w>\",\n",
      "\"2\": \"</s>\",\n",
      "\"42384\": \"<unk>\",\n",
      "\"42385\": \"<unk>\",\n",
      "\"42386\": \"<unk>\",\n",
      "\"42387\": \"<unk>\",\n",
      "\"42388\": \"<unk>\",\n",
      "\"42389\": \"<unk>\",\n",
      "\"42390\": \"<unk>\",\n",
      "\"42391\": \"<unk>\",\n",
      "\"42392\": \"<unk>\",\n"
     ]
    }
   ],
   "source": [
    "for token_id in test_data['text_tokens_with_prefix'][0]:\n",
    "    print(f'\"{token_id.item()}\": \"{tokenizer.convert_ids_to_tokens([token_id])[0]}\",')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top-5 most possible tokens are:\n",
      "[(['the</w>'], 0.9999977350234985), (['<unk>'], 7.513795026170556e-07), (['an</w>'], 6.147940894152271e-07), (['<unk>'], 5.747674549638759e-07), (['their</w>'], 4.162162952070503e-07)]\n",
      "output_text: the\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['interaction</w>'], 0.9999583959579468), (['interactions</w>'], 3.52180541085545e-05), (['interacting</w>'], 2.646220082169748e-06), (['association</w>'], 2.0857401068496983e-06), (['relationship</w>'], 1.6648806422381313e-06)]\n",
      "output_text: the interaction\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['between</w>'], 0.9999723434448242), (['of</w>'], 2.2286027160589583e-05), (['with</w>'], 2.8870240385003854e-06), (['is</w>'], 1.272347390113282e-06), (['(</w>'], 1.2038821068927064e-06)]\n",
      "output_text: the interaction between\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['7</w>'], 0.2845838963985443), (['1'], 0.21450771391391754), (['n'], 0.18082371354103088), (['l</w>'], 0.1680757701396942), (['1-</w>'], 0.15200898051261902)]\n",
      "The token has the 2 / 42393 biggest probability in output.\n",
      "output_text: the interaction between 1\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['h</w>'], 0.9929198622703552), (['h'], 0.006682639941573143), (['hr</w>'], 0.0001902982621686533), (['r</w>'], 0.00011132079089293256), (['i</w>'], 9.588200191501528e-05)]\n",
      "output_text: the interaction between 1h\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['@-@</w>'], 0.9996311664581299), (['(</w>'], 0.0001502049999544397), (['indole</w>'], 0.000125614256830886), ([',</w>'], 7.417867163894698e-05), (['&#91;</w>'], 1.878326293081045e-05)]\n",
      "output_text: the interaction between 1h-\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['ind'], 0.8956053853034973), (['indole</w>'], 0.09212328493595123), (['indol'], 0.006172205321490765), (['in'], 0.0032604087609797716), (['benzo</w>'], 0.0028388123027980328)]\n",
      "output_text: the interaction between 1h-ind\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['azole</w>'], 0.9766125679016113), (['azol</w>'], 0.022582339122891426), (['azol'], 0.0004426431260071695), (['azoles</w>'], 0.00018650077981874347), (['azolin</w>'], 0.00017591787036508322)]\n",
      "output_text: the interaction between 1h-indazole\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['@-@</w>'], 0.9945486187934875), (['and</w>'], 0.002816095482558012), (['derivative</w>'], 0.0021457585971802473), (['carboxamide</w>'], 0.0002933957439381629), (['&#91;</w>'], 0.00019603862892836332)]\n",
      "output_text: the interaction between 1h-indazole-\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['7</w>'], 0.9765378832817078), (['3</w>'], 0.014969746582210064), (['7'], 0.004476774018257856), (['2</w>'], 0.0028925237711519003), (['5</w>'], 0.0011230200761929154)]\n",
      "output_text: the interaction between 1h-indazole-7\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['@-@</w>'], 0.9999896287918091), (['(</w>'], 5.556681571761146e-06), (['/</w>'], 2.185533958254382e-06), (['&apos;</w>'], 1.4942645520932274e-06), (['carboxamide</w>'], 1.2345983577688457e-06)]\n",
      "output_text: the interaction between 1h-indazole-7-\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['carb'], 0.881027102470398), (['carboxamide</w>'], 0.09869854152202606), (['carboxylic</w>'], 0.013884804211556911), (['carbox'], 0.004492256324738264), (['carboxylate</w>'], 0.0018972912803292274)]\n",
      "output_text: the interaction between 1h-indazole-7-carb\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['onitrile</w>'], 0.962281346321106), (['onitr'], 0.037378083914518356), (['on'], 0.00012627591786440462), (['o</w>'], 0.00011745002120733261), (['azole</w>'], 9.676389890955761e-05)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['and</w>'], 0.998705267906189), (['(</w>'], 0.000598996237386018), (['@-@</w>'], 0.0002924086875282228), (['derivative</w>'], 0.0002242808841401711), (['hydrochloride</w>'], 0.00017905260028783232)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['nitric</w>'], 0.9865708947181702), (['neuronal</w>'], 0.005296696443110704), (['endothelial</w>'], 0.0050214440561831), (['nos</w>'], 0.0019181991228833795), (['inducible</w>'], 0.0011927374871447682)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['@-@</w>'], 0.8197457194328308), (['oxide</w>'], 0.18007491528987885), (['/</w>'], 0.0001311234664171934), (['acid</w>'], 2.63989859377034e-05), (['synthase</w>'], 2.1804946300107986e-05)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['oxide</w>'], 0.9999653100967407), (['ox'], 1.4435100638365839e-05), (['acid</w>'], 8.43391171656549e-06), (['oxidase</w>'], 6.6131592575402465e-06), (['Oxide</w>'], 5.15915189680527e-06)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['synthase</w>'], 0.9980332255363464), (['synthases</w>'], 0.0007742302259430289), (['synth'], 0.0006508043152280152), (['synthetase</w>'], 0.000284143490716815), (['@-@</w>'], 0.0002575344988144934)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['brain</w>'], 0.6071934700012207), (['endothelial</w>'], 0.22852028906345367), (['inducible</w>'], 0.13816140592098236), ([',</w>'], 0.018788596615195274), (['neuronal</w>'], 0.007336209528148174)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['(</w>'], 0.9957018494606018), ([',</w>'], 0.0021794976200908422), (['type</w>'], 0.0012634311569854617), (['1</w>'], 0.0005443659611046314), (['isoform</w>'], 0.0003109015815425664)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['nos'], 0.9984521865844727), (['nos</w>'], 0.0011499135289341211), (['no'], 0.0002006310096476227), (['b'], 0.00012573345156852156), (['no</w>'], 7.158859079936519e-05)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (nos\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['1</w>'], 0.9367640614509583), (['2</w>'], 0.04736614227294922), (['3</w>'], 0.011928846128284931), (['2b</w>'], 0.003206639550626278), (['1b</w>'], 0.0007343050092458725)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (nos1\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[([')</w>'], 0.9999239444732666), (['or</w>'], 2.95987611025339e-05), (['?</w>'], 2.7306745323585346e-05), (['&#93;</w>'], 1.1899413948412985e-05), (['and</w>'], 7.3167252594430465e-06)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (nos1)\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['is</w>'], 0.9999744892120361), (['and</w>'], 7.687463039474096e-06), ([',</w>'], 6.920304258528631e-06), ([';</w>'], 6.81998335494427e-06), (['or</w>'], 4.049077688250691e-06)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (nos1) is\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['inhibitor</w>'], 0.993704617023468), (['modulator</w>'], 0.00442323787137866), (['antagonist</w>'], 0.0014723590575158596), (['binder</w>'], 0.000217506691114977), (['blocker</w>'], 0.00018228004046250135)]\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (nos1) is inhibitor\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[([';</w>'], 0.7808926701545715), (['.</w>'], 0.21880914270877838), ([',</w>'], 0.00023441918892785907), (['(</w>'], 3.381192436791025e-05), (['and</w>'], 2.99403109238483e-05)]\n",
      "The token has the 2 / 42393 biggest probability in output.\n",
      "output_text: the interaction between 1h-indazole-7-carbonitrile and nitric-oxide synthase brain (nos1) is inhibitor.\n",
      "\n",
      "The top-5 most possible tokens are:\n",
      "[(['</s>'], 0.9999818801879883), (['<unk>'], 9.191899152938277e-06), ([';</w>'], 6.016460702085169e-06), (['.</w>'], 2.058118070635828e-06), (['?</w>'], 9.817501904763049e-07)]\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "test_input = test_data['text_tokens_with_prefix']\n",
    "\n",
    "output_text = []\n",
    "k = 5\n",
    "prob = []\n",
    "ranking = []\n",
    "step = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    m.models[0].decoder.eval()\n",
    "    step += 1\n",
    "\n",
    "    out = m.models[0].decoder(test_input)\n",
    "\n",
    "    softmax_out = torch.softmax(out[0][0][-1], dim=-1)\n",
    "    _, top_k_indices = torch.topk(out[0][0][-1], k=k)\n",
    "    top_k_tokens = [tokenizer.convert_ids_to_tokens([indice]) for indice in top_k_indices]\n",
    "    top_k_probs = torch.softmax(out[0][0][-1][top_k_indices], dim=-1)\n",
    "    top_k = [(token, prob.item()) for token, prob in zip(top_k_tokens, top_k_probs)]\n",
    "    print(f'The top-{k} most possible tokens are:\\n{top_k}')\n",
    "    next_token_id = int(input('Please input the next token:'))\n",
    "    test_input = torch.cat([test_input[0], top_k_indices[next_token_id-1].unsqueeze(0)], dim=-1).unsqueeze(0)\n",
    "    output_text.append(top_k_indices[next_token_id-1])\n",
    "\n",
    "    prob.append(softmax_out[top_k_indices[next_token_id-1]].item())\n",
    "    ranking.append(next_token_id)\n",
    "    while (next_token_id != 0):        \n",
    "        print(f'output_text: {m.decode(output_text)}\\n')\n",
    "        step += 1\n",
    "\n",
    "        out = m.models[0].decoder(test_input)\n",
    "        softmax_out = torch.softmax(out[0][0][-1], dim=-1)\n",
    "        _, top_k_indices = torch.topk(out[0][0][-1], k=k)\n",
    "        top_k_tokens = [tokenizer.convert_ids_to_tokens([indice]) for indice in top_k_indices]\n",
    "        top_k_probs = torch.softmax(out[0][0][-1][top_k_indices], dim=-1)\n",
    "        top_k = [(token, prob.item()) for token, prob in zip(top_k_tokens, top_k_probs)]\n",
    "        print(f'The top-{k} most possible tokens are:\\n{top_k}')\n",
    "        next_token_id = int(input('Please input the next token (0 to end, -1 to input Customized string):'))\n",
    "        if next_token_id == 0:\n",
    "            break\n",
    "        if next_token_id == -1:\n",
    "            customized_string = input('Please input the Customized string:')\n",
    "            customized_string_tokens = torch.tensor(tokenizer.convert_tokens_to_ids(customized_string)).unsqueeze(0).cuda()\n",
    "            test_input = torch.cat([test_input[0], customized_string_tokens], dim=-1).unsqueeze(0)\n",
    "            output_text.append(customized_string_tokens.squeeze(0))\n",
    "\n",
    "            customized_string_prob = out[0][0][-1][customized_string_tokens].clone()\n",
    "            sorted_output, _ = torch.sort(out[0][0][-1], descending=True)\n",
    "            print(f'The {customized_string} has the {torch.where(sorted_output == customized_string_prob)[0].item() + 1} / {len(sorted_output)} biggest probability in output.')\n",
    "            \n",
    "            prob.append(softmax_out[customized_string_tokens].item())\n",
    "            ranking.append(torch.where(sorted_output == customized_string_prob)[0].item() + 1)\n",
    "\n",
    "            continue\n",
    "        if next_token_id != 1:\n",
    "            print(f'The token has the {next_token_id} / {len(sorted_output)} biggest probability in output.')\n",
    "        test_input = torch.cat([test_input[0], top_k_indices[next_token_id-1].unsqueeze(0)], dim=-1).unsqueeze(0)\n",
    "        output_text.append(top_k_indices[next_token_id-1])\n",
    "\n",
    "        prob.append(softmax_out[top_k_indices[next_token_id-1]].item())\n",
    "        ranking.append(next_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create some fake data.\n",
    "x = np.arange(step-1)\n",
    "y1 = prob\n",
    "y2 = ranking\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "fig.suptitle(f'Pmid: {test_data[\"pmid\"]}')\n",
    "\n",
    "ax1.plot(x, y1, '.-')\n",
    "ax1.set_ylabel('Probability')\n",
    "\n",
    "ax2.plot(x, y2, '.-')\n",
    "ax2.set_xlabel('step')\n",
    "ax2.set_ylabel('Ranking')\n",
    "\n",
    "marks = [0]* (step-1)\n",
    "mark = False\n",
    "\n",
    "# 0 for  parttern tokens, 1 for drugs ,2 for targets, 3 for interaction\n",
    "for i, token in enumerate(output_text):\n",
    "    if token != 6 and output_text[i-1] == 45:\n",
    "        marks[i] = 1\n",
    "        mark = True\n",
    "        continue\n",
    "    if token == 8 or token == 21 or token == 4:\n",
    "        continue\n",
    "    if token != 6 and output_text[i-1] == 8:\n",
    "        marks[i] = 2\n",
    "        mark = True\n",
    "        continue\n",
    "    if token != 6 and output_text[i-1] == 21:\n",
    "        marks[i] = 3\n",
    "        mark = True\n",
    "        continue\n",
    "    if token == 44:\n",
    "        mark = False\n",
    "        continue\n",
    "    if mark:\n",
    "        marks[i] = marks[i-1]\n",
    "        \n",
    "\n",
    "# if marks[x] == 1, then using hollow circle for the plot, if marks[x] == 2, then using hollow triangle for the plot, if marks[x] == 3, then using star for the plot.\n",
    "for i in range(step-1):\n",
    "    if marks[i] == 1:\n",
    "        ax1.plot(x[i], y1[i], marker='o', color='white', markeredgecolor='blue')\n",
    "        ax2.plot(x[i], y2[i], marker='o', color='white', markeredgecolor='blue')\n",
    "        if y2[i] > 5:\n",
    "            ax1.plot(x[i], y1[i], marker='o', color='white', markeredgecolor='red')\n",
    "            ax2.plot(x[i], y2[i], marker='o', color='white', markeredgecolor='red')\n",
    "\n",
    "    if marks[i] == 2:\n",
    "        ax1.plot(x[i], y1[i], marker='^', color='white', markeredgecolor='blue')\n",
    "        ax2.plot(x[i], y2[i], marker='^', color='white', markeredgecolor='blue')\n",
    "        if y2[i] > 5:\n",
    "            ax1.plot(x[i], y1[i], marker='^', color='red')\n",
    "            ax2.plot(x[i], y2[i], marker='^', color='red')\n",
    "\n",
    "    if marks[i] == 3:\n",
    "        ax1.plot(x[i], y1[i], marker='x', color='white', markeredgecolor='blue')\n",
    "        ax2.plot(x[i], y2[i], marker='x', color='white', markeredgecolor='blue')\n",
    "        if y2[i] > 5:\n",
    "            ax1.plot(x[i], y1[i], marker='x', color='red')\n",
    "            ax2.plot(x[i], y2[i], marker='x', color='red')\n",
    "\n",
    "\n",
    "plt.savefig(f'analysis/img/{test_data[\"pmid\"]}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
