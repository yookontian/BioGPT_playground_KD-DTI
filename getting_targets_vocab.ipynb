{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://go.drugbank.com/bio_entities/BE0000180\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "entity_name = soup.find(\"h1\").text\n",
    "main_tag = soup.find('main')\n",
    "syn_link = main_tag.find('a', href=lambda href: href and href.startswith('/'))\n",
    "link = f\"https://go.drugbank.com{syn_link['href']}\"\n",
    "\n",
    "response = requests.get(link)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "synonyms_section = soup.find('dt', {'id': 'synonyms'})\n",
    "synonyms_list = synonyms_section.find_next('ul')\n",
    "syns = [synonym.text for synonym in synonyms_list if synonym.text != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_name(id):\n",
    "    url = f\"https://go.drugbank.com/bio_entities/{id}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    entity_name = soup.find(\"h1\").text\n",
    "    main_tag = soup.find('main')\n",
    "    if (entity_name == \"This page doesn't exist. What a pain.\"):\n",
    "        syns = 0\n",
    "    else:\n",
    "        try:\n",
    "            syn_link = main_tag.find('a', href=lambda href: href and href.startswith('/'))\n",
    "        \n",
    "            link = f\"https://go.drugbank.com{syn_link['href']}\"\n",
    "\n",
    "            response = requests.get(link)\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            try:\n",
    "                synonyms_section = soup.find('dt', {'id': 'synonyms'})\n",
    "                synonyms_list = synonyms_section.find_next('ul')\n",
    "                syns = [synonym.text for synonym in synonyms_list if synonym.text != '\\n']\n",
    "            except:\n",
    "                syns = 0\n",
    "        except:\n",
    "            syns = 0\n",
    "\n",
    "    return entity_name, syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target names only\n",
    "# id :BE0000001~BE0010215\n",
    "# parallel crawler\n",
    "num_targets = 10215\n",
    "num_workers = 3\n",
    "freq = 0.8\n",
    "\n",
    "target_vocabulary = {}\n",
    "\n",
    "for n in range(1, num_targets+1, num_workers):\n",
    "\n",
    "    ids = [str(f'BE00{(5-len(str(i)))*\"0\"}{i}') for i in range(n, n+num_workers)]\n",
    "    if n + num_workers > num_targets:\n",
    "        ids = [str(f'BE00{(5-len(str(i)))*\"0\"}{i}') for i in range(n, num_targets+1)]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers ) as executor:\n",
    "        results = executor.map(get_entity_name, ids)\n",
    "        # for result in results:\n",
    "        #     print(result)\n",
    "\n",
    "    for id, entity_name in zip(ids, results):\n",
    "        target_vocabulary[id] = entity_name\n",
    "    # print(entity_name)\n",
    "\n",
    "    if (n - 1) % 99 == 0:\n",
    "        with open('./DBid_to_names/target vocabulary.json', 'w') as f:\n",
    "            f.write(json.dumps(target_vocabulary))\n",
    "\n",
    "    time.sleep(freq)\n",
    "\n",
    "with open('./DBid_to_names/target vocabulary.json', 'w') as f:\n",
    "    f.write(json.dumps(target_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get syn\n",
    "# id :BE0000001~BE0010215\n",
    "# parallel crawler\n",
    "num_targets = 10215\n",
    "num_workers = 3\n",
    "freq = 0.5\n",
    "\n",
    "# target_vocabulary = {}\n",
    "# target_syn_vocabulary = {}\n",
    "\n",
    "for n in range(7235, num_targets+1, num_workers):\n",
    "\n",
    "    ids = [str(f'BE00{(5-len(str(i)))*\"0\"}{i}') for i in range(n, n+num_workers)]\n",
    "    if n + num_workers > num_targets:\n",
    "        ids = [str(f'BE00{(5-len(str(i)))*\"0\"}{i}') for i in range(n, num_targets+1)]\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = executor.map(get_entity_name, ids)\n",
    "        # for result in results:\n",
    "        #     print(result)\n",
    "\n",
    "    for id, (entity_name, syn_names) in zip(ids, results):\n",
    "        # target_vocabulary[id] = entity_name\n",
    "        if entity_name != \"This page doesn't exist. What a pain.\":\n",
    "            target_syn_vocabulary[entity_name] = syn_names\n",
    "    # print(entity_name)\n",
    "\n",
    "    if (n - 1) % 99 == 0:\n",
    "        # retain 2 decimals while print out the progress n / num_targets\n",
    "        print(f'{((n + 1) / num_targets):.2%}')\n",
    "        with open('/home/tian/Projects/MyReaserch/DBid_to_names/target vocabulary w syn.json', 'w') as f:\n",
    "            f.write(json.dumps(target_syn_vocabulary))\n",
    "\n",
    "    time.sleep(freq)\n",
    "\n",
    "with open('/home/tian/Projects/MyReaserch/DBid_to_names/target vocabulary w syn.json', 'w') as f:\n",
    "    f.write(json.dumps(target_syn_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10214"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5205"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_syn_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/tian/Projects/MyReaserch/DBid_to_names/target vocabulary w syn.json', 'w') as f:\n",
    "    f.write(json.dumps(target_syn_vocabulary, indent=4, separators=(\", \", \": \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10215"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_vocabulary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
